# Awesome-Foundation-Models
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of foundation models for vision and language tasks. Papers without code are not included.

## Papers

### Survey

* [2023.03] A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT [[PDF]](https://arxiv.org/pdf/2302.09419.pdf)
* [2022.07] On the Opportunities and Risks of Foundation Models [[PDF]](https://arxiv.org/pdf/2108.07258.pdf)

### 2023

* UNINEXT: Universal Instance Perception as Object Discovery and Retrieval, CVPR 2023, [[PDF]](https://arxiv.org/pdf/2303.06674.pdf) [[Code]](https://github.com/MasterBin-IIAU/UNINEXT)
* InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions [[PDF]](https://arxiv.org/pdf/2211.05778.pdf) [[Code]](https://github.com/OpenGVLab/InternImage)
* Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models [[PDF]](https://arxiv.org/pdf/2303.04671.pdf) [[Code]](https://github.com/microsoft/visual-chatgpt)

### 2022

* Video Swin Transformer, CVPR 2022, [[PDF]](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Video_Swin_Transformer_CVPR_2022_paper.pdf) [[Code]](https://github.com/SwinTransformer/Video-Swin-Transformer)
* FLAVA: A Foundational Language And Vision Alignment Model, CVPR 2022, [[PDF]](https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.pdf) [[Code]](https://github.com/facebookresearch/multimodal/tree/main/examples/flava)

### 2021

* Swin Transformer: Hierarchical Vision Transformer using Shifted Windows, ICCV 2021, [[PDF]](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.pdf) [[Code]](https://github.com/microsoft/Swin-Transformer)
* An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale, ICLR 2021, [[PDF]](https://arxiv.org/pdf/2010.11929.pdf) [[Code]](https://github.com/google-research/vision_transformer)
