# Awesome-Foundation-Models
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of foundation models for vision and language tasks. Papers without code are not included.

## What is a foundation model? 
In recent years, a new successful paradigm for building AI systems has emerged: Train one model on a huge amount of data and adapt it to many applications. We call such a model a foundation model. Learn more from [https://crfm.stanford.edu/](https://crfm.stanford.edu/).

## Papers

### Survey

* [2023.03] [A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT](https://arxiv.org/pdf/2302.09419.pdf)
* [2022.07] [On the Opportunities and Risks of Foundation Models](https://arxiv.org/pdf/2108.07258.pdf)

### 2023

* [GPT-4 Technical Report](https://arxiv.org/pdf/2303.08774.pdf) (from OpenAI)
* [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models.](https://arxiv.org/pdf/2303.04671.pdf) (from Microsoft Research Asia)
* [UNINEXT: Universal Instance Perception as Object Discovery and Retrieval.](https://arxiv.org/pdf/2303.06674.pdf) (CVPR, from ByteDance)
* [InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions.](https://arxiv.org/pdf/2211.05778.pdf) (CVPR, from Shanghai AI Laboratory)

### 2022

* [Video Swin Transformer.](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Video_Swin_Transformer_CVPR_2022_paper.pdf) (CVPR, from Microsoft Research Asia)
* [FLAVA: A Foundational Language And Vision Alignment Model.](https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.pdf) (CVPR, from Facebook AI Research)
* [Towards artificial general intelligence via a multimodal foundation model.](https://www.nature.com/articles/s41467-022-30761-2) (Nature Communication, from Renmin University of China)

### 2021

* [CLIP: Learning Transferable Visual Models From Natural Language Supervision.](https://arxiv.org/pdf/2103.00020.pdf) (from OpenAI)
* [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows.](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.pdf) (ICCV, from Microsoft Research Asia)
* [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.](https://arxiv.org/pdf/2010.11929.pdf) (ICLR, from Google)

### 2020

* [GPT-3: Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf) (from OpenAI)

### 2019

* [GPT-2: Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf) (from OpenAI)

### 2017

* [Attention Is All You Need.](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) (NeurIPS, from Google)
